{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gSKvOoyQISKghL0-QV2woII2kcf6FcPp","timestamp":1665587802252}],"collapsed_sections":[]},"kernelspec":{"display_name":"tensorflow","language":"python","name":"tensorflow"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SlRhd8PbjyEj"},"source":["## Using Keras to Build and Train Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"JB5OC-96jyEk"},"source":["In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n","\n","## UCI Pima Diabetes Dataset\n","\n","* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n","\n","\n","### Attributes: (all numeric-valued)\n","   1. Number of times pregnant\n","   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","   3. Diastolic blood pressure (mm Hg)\n","   4. Triceps skin fold thickness (mm)\n","   5. 2-Hour serum insulin (mu U/ml)\n","   6. Body mass index (weight in kg/(height in m)^2)\n","   7. Diabetes pedigree function\n","   8. Age (years)\n","   9. Class variable (0 or 1)"]},{"cell_type":"markdown","metadata":{"id":"8NCgdfnwjyEl"},"source":["The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."]},{"cell_type":"code","metadata":{"id":"HWPJPGG3jyEm"},"source":["#Preliminaries\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDVDuv86jyEr"},"source":["## Import Keras objects for Deep Learning\n","import tensorflow as tf\n","\n","from tensorflow.keras.models  import Sequential\n","from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fcMO7fnjjyEx"},"source":["## Load in the data set (Internet Access needed)\n","\n","url = \"https://raw.githubusercontent.com/rzese/Corso_Deep_Learning_UNIFE/master/diabetes.csv\"\n","names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n","         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n","diabetes_df = pd.read_csv(url, names=names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AEiuwhmjyEz","colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"status":"ok","timestamp":1636555344409,"user_tz":-60,"elapsed":221,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"6a8e2789-3075-437a-8b8e-547d2900cee0"},"source":["# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n","print(diabetes_df.shape)\n","diabetes_df.sample(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(768, 9)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>times_pregnant</th>\n","      <th>glucose_tolerance_test</th>\n","      <th>blood_pressure</th>\n","      <th>skin_thickness</th>\n","      <th>insulin</th>\n","      <th>bmi</th>\n","      <th>pedigree_function</th>\n","      <th>age</th>\n","      <th>has_diabetes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>671</th>\n","      <td>1</td>\n","      <td>99</td>\n","      <td>58</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>25.4</td>\n","      <td>0.551</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>569</th>\n","      <td>0</td>\n","      <td>121</td>\n","      <td>66</td>\n","      <td>30</td>\n","      <td>165</td>\n","      <td>34.3</td>\n","      <td>0.203</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>640</th>\n","      <td>0</td>\n","      <td>102</td>\n","      <td>86</td>\n","      <td>17</td>\n","      <td>105</td>\n","      <td>29.3</td>\n","      <td>0.695</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>4</td>\n","      <td>144</td>\n","      <td>58</td>\n","      <td>28</td>\n","      <td>140</td>\n","      <td>29.5</td>\n","      <td>0.287</td>\n","      <td>37</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>759</th>\n","      <td>6</td>\n","      <td>190</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.5</td>\n","      <td>0.278</td>\n","      <td>66</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     times_pregnant  glucose_tolerance_test  ...  age  has_diabetes\n","671               1                      99  ...   21             0\n","569               0                     121  ...   33             1\n","640               0                     102  ...   27             0\n","107               4                     144  ...   37             0\n","759               6                     190  ...   66             1\n","\n","[5 rows x 9 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Jg6pE-ngjyE3"},"source":["X = diabetes_df.iloc[:, :-1].values  # separo le x dalle etichette\n","y = diabetes_df[\"has_diabetes\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7_tzE2njyE7"},"source":["# Split the data to Train, and Test (75%, 25%)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111) # random_state is the seed for random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIKfTi18jyE9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636555529053,"user_tz":-60,"elapsed":218,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"9753fcd7-e260-428e-cd96-e18ba1a6d5c8"},"source":["np.mean(y), np.mean(1-y) # media di quanti hanno etichetta 1 e quanti 0\n","# è un dataset sblianciato"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.3489583333333333, 0.6510416666666666)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"-utPDVYyjyFB"},"source":["Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n","## Exercise: Get a baseline performance using Random Forest\n","To begin, and get a baseline for classifier performance:\n","1. Train a Random Forest model with 200 trees on the training data.\n","2. Calculate the accuracy and roc_auc_score of the predictions."]},{"cell_type":"code","metadata":{"id":"CxU2iVCBjyFC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636555695249,"user_tz":-60,"elapsed":615,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"12e142c5-8afb-40df-da81-0ec5b7933f3f"},"source":["## Train the RF Model\n","# creo un accuracy di partenza, poi non voglio scendere sotto questo minimo\n","rf_model = RandomForestClassifier(n_estimators=200) # n_estimator is the number of trees in the forest\n","rf_model.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=200,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"-WKIatJ1jyFG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636555745839,"user_tz":-60,"elapsed":366,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"476b222c-2938-4927-f829-4554f65f19f6"},"source":["# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n","y_pred_class_rf = rf_model.predict(X_test)\n","y_pred_prob_rf = rf_model.predict_proba(X_test)\n","\n","\n","print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n","print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))\n","#calcolo anche la roc perchè il dataset è sblianciato\n","#accuracy di 0.75 non è male ma roc indica che va molto meglio (82%)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is 0.750\n","roc-auc is 0.826\n"]}]},{"cell_type":"code","metadata":{"id":"5tZ_WFOUjyFK","colab":{"base_uri":"https://localhost:8080/","height":499},"executionInfo":{"status":"ok","timestamp":1636555843588,"user_tz":-60,"elapsed":743,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"ba347eea-35eb-40ca-ac5e-d1336af6ff76"},"source":["def plot_roc(y_test, y_pred, model_name):\n","    fpr, tpr, thr = roc_curve(y_test, y_pred)\n","    fig, ax = plt.subplots(figsize=(8, 8))\n","    ax.plot(fpr, tpr, 'k-')\n","    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n","    ax.grid(True)\n","    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n","           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n","\n","\n","plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"5pLMJCBpjyFN"},"source":["## Build a Single Hidden Layer Neural Network\n","\n","We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."]},{"cell_type":"code","source":[],"metadata":{"id":"SddnAu49z13U"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfhkW-LYjyFO"},"source":["## First let's normalize the data -> sono su delle scale MOOOLTO diverse\n","## This aids the training of neural nets by providing numerical stability\n","## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n","\n","#effettuo una normalizzazione\n","normalizer = StandardScaler()\n","X_train_norm = normalizer.fit_transform(X_train) #cerca il modo migliore per modificare il dataset e trasforma\n","X_test_norm = normalizer.transform(X_test) #usa l'ultimo modo utilizzato per modificare (usa xmin e xmax precedenti)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCznOl0SjyFR"},"source":["# Define the Model \n","# Input size is 8-dimensional\n","# 1 hidden layer, 12 hidden nodes (8 in questo caso), sigmoid activation\n","# Final layer has just one node with a sigmoid activation (standard for binary classification)\n","\n","model_1 = Sequential([\n","    Dense(8, input_shape=(8,), activation=\"relu\"),\n","    Dense(1, activation=\"sigmoid\")\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sWTvBnajyFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636556914996,"user_tz":-60,"elapsed":424,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"4f99d5e9-dbba-4143-9e0b-a291e302368c"},"source":["#  This is a nice tool to view the model you have created and count the parameters\n","\n","model_1.summary() #i parametri sono 121 (81) 8 neuroni inizio, 12 neuroni strato interno, 1 neurone uscita (9*12 + 13*1 non 8 perchè c'è il bias quindi vede 9 ingressi)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_5 (Dense)             (None, 8)                 72        \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 81\n","Trainable params: 81\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"wjx3tm0TjyFa"},"source":["### Comprehension question:\n","Why do we have 121 parameters?  Does that make sense?\n","\n","\n","Let's fit our model for 200 epochs."]},{"cell_type":"code","metadata":{"id":"9JpnPz3TjyFc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636556931731,"user_tz":-60,"elapsed":14815,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"d4fd778c-2af3-4f4e-eef7-3f9344a517bd"},"source":["# Fit(Train) the Model\n","\n","# Compile the model with Optimizer, Loss Function and Metrics\n","# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n","\n","model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n","run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n","# the fit function returns the run history. \n","# model_1.fit non riparte da zero finchè lo script è in esecuzione (continua ad andare avanti)\n","# It is very convenient, as it contains information about the model fit, iterations etc."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","18/18 [==============================] - 1s 11ms/step - loss: 0.7276 - accuracy: 0.5347 - val_loss: 0.7154 - val_accuracy: 0.5365\n","Epoch 2/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.5469 - val_loss: 0.7091 - val_accuracy: 0.5417\n","Epoch 3/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7142 - accuracy: 0.5469 - val_loss: 0.7031 - val_accuracy: 0.5417\n","Epoch 4/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.5642 - val_loss: 0.6974 - val_accuracy: 0.5469\n","Epoch 5/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.5747 - val_loss: 0.6920 - val_accuracy: 0.5521\n","Epoch 6/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.5885 - val_loss: 0.6868 - val_accuracy: 0.5521\n","Epoch 7/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5938 - val_loss: 0.6819 - val_accuracy: 0.5573\n","Epoch 8/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5955 - val_loss: 0.6772 - val_accuracy: 0.5573\n","Epoch 9/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.6007 - val_loss: 0.6728 - val_accuracy: 0.5625\n","Epoch 10/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.6076 - val_loss: 0.6686 - val_accuracy: 0.5625\n","Epoch 11/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.6076 - val_loss: 0.6646 - val_accuracy: 0.5729\n","Epoch 12/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.6146 - val_loss: 0.6607 - val_accuracy: 0.5781\n","Epoch 13/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6250 - val_loss: 0.6570 - val_accuracy: 0.5833\n","Epoch 14/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6319 - val_loss: 0.6535 - val_accuracy: 0.5885\n","Epoch 15/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6354 - val_loss: 0.6501 - val_accuracy: 0.5833\n","Epoch 16/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.6468 - val_accuracy: 0.5833\n","Epoch 17/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6458 - val_loss: 0.6437 - val_accuracy: 0.5833\n","Epoch 18/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6493 - val_loss: 0.6407 - val_accuracy: 0.5885\n","Epoch 19/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6493 - val_loss: 0.6378 - val_accuracy: 0.5938\n","Epoch 20/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6545 - val_loss: 0.6350 - val_accuracy: 0.5990\n","Epoch 21/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6562 - val_loss: 0.6323 - val_accuracy: 0.6042\n","Epoch 22/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6297 - val_accuracy: 0.6042\n","Epoch 23/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6597 - val_loss: 0.6272 - val_accuracy: 0.6146\n","Epoch 24/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6597 - val_loss: 0.6248 - val_accuracy: 0.6094\n","Epoch 25/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6632 - val_loss: 0.6224 - val_accuracy: 0.6146\n","Epoch 26/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6615 - val_loss: 0.6202 - val_accuracy: 0.6198\n","Epoch 27/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6580 - val_loss: 0.6180 - val_accuracy: 0.6250\n","Epoch 28/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6597 - val_loss: 0.6159 - val_accuracy: 0.6250\n","Epoch 29/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6562 - val_loss: 0.6138 - val_accuracy: 0.6302\n","Epoch 30/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.6545 - val_loss: 0.6118 - val_accuracy: 0.6302\n","Epoch 31/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6580 - val_loss: 0.6098 - val_accuracy: 0.6250\n","Epoch 32/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6580 - val_loss: 0.6079 - val_accuracy: 0.6302\n","Epoch 33/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6597 - val_loss: 0.6061 - val_accuracy: 0.6250\n","Epoch 34/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6597 - val_loss: 0.6043 - val_accuracy: 0.6302\n","Epoch 35/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6580 - val_loss: 0.6025 - val_accuracy: 0.6198\n","Epoch 36/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6562 - val_loss: 0.6008 - val_accuracy: 0.6198\n","Epoch 37/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6615 - val_loss: 0.5992 - val_accuracy: 0.6250\n","Epoch 38/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.6649 - val_loss: 0.5976 - val_accuracy: 0.6250\n","Epoch 39/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.6719 - val_loss: 0.5960 - val_accuracy: 0.6250\n","Epoch 40/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6771 - val_loss: 0.5944 - val_accuracy: 0.6302\n","Epoch 41/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6771 - val_loss: 0.5929 - val_accuracy: 0.6354\n","Epoch 42/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.6771 - val_loss: 0.5914 - val_accuracy: 0.6354\n","Epoch 43/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.6753 - val_loss: 0.5900 - val_accuracy: 0.6406\n","Epoch 44/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.6788 - val_loss: 0.5886 - val_accuracy: 0.6510\n","Epoch 45/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.6840 - val_loss: 0.5872 - val_accuracy: 0.6562\n","Epoch 46/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.6858 - val_loss: 0.5858 - val_accuracy: 0.6615\n","Epoch 47/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.6875 - val_loss: 0.5845 - val_accuracy: 0.6667\n","Epoch 48/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6892 - val_loss: 0.5832 - val_accuracy: 0.6615\n","Epoch 49/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6910 - val_loss: 0.5819 - val_accuracy: 0.6719\n","Epoch 50/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6927 - val_loss: 0.5807 - val_accuracy: 0.6719\n","Epoch 51/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.6979 - val_loss: 0.5795 - val_accuracy: 0.6875\n","Epoch 52/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7014 - val_loss: 0.5783 - val_accuracy: 0.6875\n","Epoch 53/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6979 - val_loss: 0.5772 - val_accuracy: 0.6979\n","Epoch 54/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.6944 - val_loss: 0.5760 - val_accuracy: 0.6979\n","Epoch 55/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6962 - val_loss: 0.5749 - val_accuracy: 0.7031\n","Epoch 56/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7014 - val_loss: 0.5738 - val_accuracy: 0.6979\n","Epoch 57/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6997 - val_loss: 0.5728 - val_accuracy: 0.7031\n","Epoch 58/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7014 - val_loss: 0.5717 - val_accuracy: 0.7083\n","Epoch 59/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7031 - val_loss: 0.5707 - val_accuracy: 0.7188\n","Epoch 60/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7014 - val_loss: 0.5696 - val_accuracy: 0.7240\n","Epoch 61/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7014 - val_loss: 0.5686 - val_accuracy: 0.7240\n","Epoch 62/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7014 - val_loss: 0.5677 - val_accuracy: 0.7292\n","Epoch 63/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7049 - val_loss: 0.5667 - val_accuracy: 0.7292\n","Epoch 64/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7066 - val_loss: 0.5658 - val_accuracy: 0.7292\n","Epoch 65/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7083 - val_loss: 0.5649 - val_accuracy: 0.7292\n","Epoch 66/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7135 - val_loss: 0.5640 - val_accuracy: 0.7240\n","Epoch 67/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7135 - val_loss: 0.5631 - val_accuracy: 0.7240\n","Epoch 68/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7118 - val_loss: 0.5622 - val_accuracy: 0.7240\n","Epoch 69/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7118 - val_loss: 0.5614 - val_accuracy: 0.7240\n","Epoch 70/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7153 - val_loss: 0.5606 - val_accuracy: 0.7240\n","Epoch 71/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7170 - val_loss: 0.5597 - val_accuracy: 0.7188\n","Epoch 72/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7240 - val_loss: 0.5589 - val_accuracy: 0.7188\n","Epoch 73/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7257 - val_loss: 0.5581 - val_accuracy: 0.7188\n","Epoch 74/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7257 - val_loss: 0.5573 - val_accuracy: 0.7188\n","Epoch 75/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7257 - val_loss: 0.5565 - val_accuracy: 0.7292\n","Epoch 76/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7222 - val_loss: 0.5557 - val_accuracy: 0.7292\n","Epoch 77/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7240 - val_loss: 0.5549 - val_accuracy: 0.7344\n","Epoch 78/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7222 - val_loss: 0.5541 - val_accuracy: 0.7292\n","Epoch 79/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7205 - val_loss: 0.5533 - val_accuracy: 0.7292\n","Epoch 80/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.7292\n","Epoch 81/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7240 - val_loss: 0.5518 - val_accuracy: 0.7292\n","Epoch 82/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7257 - val_loss: 0.5511 - val_accuracy: 0.7292\n","Epoch 83/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7292 - val_loss: 0.5503 - val_accuracy: 0.7292\n","Epoch 84/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7292 - val_loss: 0.5496 - val_accuracy: 0.7292\n","Epoch 85/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7309 - val_loss: 0.5489 - val_accuracy: 0.7292\n","Epoch 86/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7309 - val_loss: 0.5482 - val_accuracy: 0.7240\n","Epoch 87/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7326 - val_loss: 0.5475 - val_accuracy: 0.7240\n","Epoch 88/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7344 - val_loss: 0.5468 - val_accuracy: 0.7240\n","Epoch 89/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7344 - val_loss: 0.5461 - val_accuracy: 0.7292\n","Epoch 90/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7431 - val_loss: 0.5454 - val_accuracy: 0.7292\n","Epoch 91/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7448 - val_loss: 0.5447 - val_accuracy: 0.7292\n","Epoch 92/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7465 - val_loss: 0.5440 - val_accuracy: 0.7292\n","Epoch 93/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7483 - val_loss: 0.5434 - val_accuracy: 0.7292\n","Epoch 94/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7483 - val_loss: 0.5427 - val_accuracy: 0.7292\n","Epoch 95/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7483 - val_loss: 0.5421 - val_accuracy: 0.7292\n","Epoch 96/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7483 - val_loss: 0.5414 - val_accuracy: 0.7344\n","Epoch 97/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7500 - val_loss: 0.5408 - val_accuracy: 0.7396\n","Epoch 98/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7500 - val_loss: 0.5401 - val_accuracy: 0.7396\n","Epoch 99/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7500 - val_loss: 0.5395 - val_accuracy: 0.7396\n","Epoch 100/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7517 - val_loss: 0.5388 - val_accuracy: 0.7448\n","Epoch 101/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7535 - val_loss: 0.5382 - val_accuracy: 0.7448\n","Epoch 102/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7552 - val_loss: 0.5375 - val_accuracy: 0.7448\n","Epoch 103/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7552 - val_loss: 0.5369 - val_accuracy: 0.7448\n","Epoch 104/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7552 - val_loss: 0.5363 - val_accuracy: 0.7448\n","Epoch 105/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7552 - val_loss: 0.5356 - val_accuracy: 0.7396\n","Epoch 106/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7500 - val_loss: 0.5350 - val_accuracy: 0.7396\n","Epoch 107/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7396\n","Epoch 108/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7483 - val_loss: 0.5338 - val_accuracy: 0.7396\n","Epoch 109/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7465 - val_loss: 0.5332 - val_accuracy: 0.7396\n","Epoch 110/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7465 - val_loss: 0.5326 - val_accuracy: 0.7396\n","Epoch 111/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7465 - val_loss: 0.5320 - val_accuracy: 0.7396\n","Epoch 112/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7465 - val_loss: 0.5314 - val_accuracy: 0.7396\n","Epoch 113/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7448 - val_loss: 0.5308 - val_accuracy: 0.7396\n","Epoch 114/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7500 - val_loss: 0.5302 - val_accuracy: 0.7396\n","Epoch 115/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7500 - val_loss: 0.5296 - val_accuracy: 0.7448\n","Epoch 116/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5291 - val_accuracy: 0.7448\n","Epoch 117/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7500 - val_loss: 0.5285 - val_accuracy: 0.7448\n","Epoch 118/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7500 - val_loss: 0.5279 - val_accuracy: 0.7500\n","Epoch 119/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7517 - val_loss: 0.5274 - val_accuracy: 0.7500\n","Epoch 120/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7517 - val_loss: 0.5268 - val_accuracy: 0.7500\n","Epoch 121/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7535 - val_loss: 0.5263 - val_accuracy: 0.7552\n","Epoch 122/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7552 - val_loss: 0.5257 - val_accuracy: 0.7552\n","Epoch 123/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7552 - val_loss: 0.5252 - val_accuracy: 0.7552\n","Epoch 124/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7552 - val_loss: 0.5247 - val_accuracy: 0.7552\n","Epoch 125/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7552 - val_loss: 0.5241 - val_accuracy: 0.7552\n","Epoch 126/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7535 - val_loss: 0.5236 - val_accuracy: 0.7552\n","Epoch 127/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.5231 - val_accuracy: 0.7552\n","Epoch 128/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7552 - val_loss: 0.5226 - val_accuracy: 0.7604\n","Epoch 129/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7552 - val_loss: 0.5222 - val_accuracy: 0.7604\n","Epoch 130/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7604\n","Epoch 131/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7552 - val_loss: 0.5212 - val_accuracy: 0.7604\n","Epoch 132/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7604\n","Epoch 133/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7552 - val_loss: 0.5202 - val_accuracy: 0.7656\n","Epoch 134/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.7656\n","Epoch 135/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7552 - val_loss: 0.5193 - val_accuracy: 0.7656\n","Epoch 136/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7552 - val_loss: 0.5188 - val_accuracy: 0.7656\n","Epoch 137/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.5184 - val_accuracy: 0.7656\n","Epoch 138/200\n","18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7552 - val_loss: 0.5179 - val_accuracy: 0.7656\n","Epoch 139/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7604\n","Epoch 140/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.5170 - val_accuracy: 0.7604\n","Epoch 141/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7569 - val_loss: 0.5165 - val_accuracy: 0.7552\n","Epoch 142/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7569 - val_loss: 0.5161 - val_accuracy: 0.7552\n","Epoch 143/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7587 - val_loss: 0.5156 - val_accuracy: 0.7552\n","Epoch 144/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7587 - val_loss: 0.5152 - val_accuracy: 0.7552\n","Epoch 145/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7587 - val_loss: 0.5148 - val_accuracy: 0.7552\n","Epoch 146/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7604 - val_loss: 0.5143 - val_accuracy: 0.7552\n","Epoch 147/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5139 - val_accuracy: 0.7552\n","Epoch 148/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7587 - val_loss: 0.5135 - val_accuracy: 0.7552\n","Epoch 149/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7552\n","Epoch 150/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7604 - val_loss: 0.5127 - val_accuracy: 0.7552\n","Epoch 151/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7639 - val_loss: 0.5123 - val_accuracy: 0.7604\n","Epoch 152/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7622 - val_loss: 0.5119 - val_accuracy: 0.7604\n","Epoch 153/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7604 - val_loss: 0.5115 - val_accuracy: 0.7604\n","Epoch 154/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5111 - val_accuracy: 0.7604\n","Epoch 155/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7639 - val_loss: 0.5108 - val_accuracy: 0.7604\n","Epoch 156/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7604\n","Epoch 157/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7622 - val_loss: 0.5101 - val_accuracy: 0.7604\n","Epoch 158/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5097 - val_accuracy: 0.7604\n","Epoch 159/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7622 - val_loss: 0.5094 - val_accuracy: 0.7604\n","Epoch 160/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7622 - val_loss: 0.5090 - val_accuracy: 0.7604\n","Epoch 161/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7622 - val_loss: 0.5087 - val_accuracy: 0.7604\n","Epoch 162/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7622 - val_loss: 0.5083 - val_accuracy: 0.7656\n","Epoch 163/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7622 - val_loss: 0.5080 - val_accuracy: 0.7656\n","Epoch 164/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7656\n","Epoch 165/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7639 - val_loss: 0.5073 - val_accuracy: 0.7656\n","Epoch 166/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7656\n","Epoch 167/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7639 - val_loss: 0.5067 - val_accuracy: 0.7656\n","Epoch 168/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7622 - val_loss: 0.5063 - val_accuracy: 0.7656\n","Epoch 169/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7639 - val_loss: 0.5060 - val_accuracy: 0.7656\n","Epoch 170/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.7656\n","Epoch 171/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7674 - val_loss: 0.5054 - val_accuracy: 0.7656\n","Epoch 172/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5051 - val_accuracy: 0.7656\n","Epoch 173/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7656\n","Epoch 174/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7656\n","Epoch 175/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 176/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7674 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 177/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7674 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 178/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7674 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 179/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7656\n","Epoch 180/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 181/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7656\n","Epoch 182/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7656\n","Epoch 183/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7708 - val_loss: 0.5019 - val_accuracy: 0.7656\n","Epoch 184/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7708 - val_loss: 0.5016 - val_accuracy: 0.7604\n","Epoch 185/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7708 - val_loss: 0.5014 - val_accuracy: 0.7604\n","Epoch 186/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7604\n","Epoch 187/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7604\n","Epoch 188/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7656\n","Epoch 189/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7656\n","Epoch 190/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7656\n","Epoch 191/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7656\n","Epoch 192/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7656\n","Epoch 193/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7656\n","Epoch 194/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7656\n","Epoch 195/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7656\n","Epoch 196/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7656\n","Epoch 197/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7656\n","Epoch 198/200\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7656\n","Epoch 199/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7656\n","Epoch 200/200\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7656\n"]}]},{"cell_type":"code","metadata":{"id":"9w2a-k3hjyFi"},"source":["## Like we did for the Random Forest, we generate two kinds of predictions\n","#  One is a hard decision, the other is a probabilitistic score.\n","y_pred_prob_nn_1 = model_1.predict(X_test_norm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CD8b1PsjyFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636556931955,"user_tz":-60,"elapsed":6,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"6cbc2b94-0e43-4e54-fab6-3703fb0aac26"},"source":["y_pred_prob_nn_1[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.41320458],\n","       [0.6179839 ],\n","       [0.26590288],\n","       [0.46745238],\n","       [0.13427511],\n","       [0.5548048 ],\n","       [0.12559402],\n","       [0.38470584],\n","       [0.73758423],\n","       [0.44328004]], dtype=float32)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDHL0KLLqvx6","executionInfo":{"status":"ok","timestamp":1636556931955,"user_tz":-60,"elapsed":4,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"49643c84-b436-46be-c8b4-097e2e173d44"},"source":["y_pred_class_nn_1 = y_pred_prob_nn_1.round()\n","y_pred_class_nn_1[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.],\n","       [1.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [1.],\n","       [0.],\n","       [0.],\n","       [1.],\n","       [0.]], dtype=float32)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"2ldZPzSQjyFx","colab":{"base_uri":"https://localhost:8080/","height":533},"executionInfo":{"status":"ok","timestamp":1636556932208,"user_tz":-60,"elapsed":256,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"d451eb00-1cbf-42d0-c0f9-d0348f11afa3"},"source":["# Print model performance and plot the roc curve\n","print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n","print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n","\n","plot_roc(y_test, y_pred_prob_nn_1, 'NN')\n","#la roc è minore rispetto a forest ma in questo caso avrebbe più senso visualizzare anche la PRCALL (minimizzo i falsi negativi per il diabete)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is 0.766\n","roc-auc is 0.816\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"29iaThAbjyF0"},"source":["There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."]},{"cell_type":"markdown","metadata":{"id":"Nl42CLpAjyF1"},"source":["Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."]},{"cell_type":"code","metadata":{"id":"itXkcZvpjyF2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636535824719,"user_tz":-60,"elapsed":41,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"374484cf-b586-4dac-aa4d-addb9ba58ce9"},"source":["run_hist_1.history.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"UDI0bKhUjyF5"},"source":["Let's plot the training loss and the validation loss over the different epochs and see how it looks."]},{"cell_type":"code","metadata":{"id":"b_LHpyKpjyF7","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1636556720956,"user_tz":-60,"elapsed":326,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"0ad78031-b1d4-445a-d5b7-753b9f3e5103"},"source":["fig, ax = plt.subplots()\n","ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n","ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n","ax.legend()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fd63e670f50>"]},"metadata":{},"execution_count":20},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"r0js_lUWjyGA"},"source":["Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kuMQcW2wjyGA","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1636556758009,"user_tz":-60,"elapsed":23839,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"a741e2d1-8593-4947-e2ee-0c08de8585fd"},"source":["## Note that when we call \"fit\" again, it picks up where it left off\n","run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7760\n","Epoch 2/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7760\n","Epoch 3/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7760\n","Epoch 4/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5018 - val_accuracy: 0.7760\n","Epoch 5/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7760\n","Epoch 6/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7760\n","Epoch 7/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7760\n","Epoch 8/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7760\n","Epoch 9/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7760\n","Epoch 10/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7760\n","Epoch 11/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7760\n","Epoch 12/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7760\n","Epoch 13/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7760\n","Epoch 14/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7760\n","Epoch 15/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 16/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 17/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 18/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 19/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7760\n","Epoch 20/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7760\n","Epoch 21/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7760\n","Epoch 22/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7760\n","Epoch 23/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.5007 - val_accuracy: 0.7760\n","Epoch 24/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7760\n","Epoch 25/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7760\n","Epoch 26/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7760\n","Epoch 27/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7760\n","Epoch 28/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7795 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 29/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 30/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 31/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 32/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 33/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7760\n","Epoch 34/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7760\n","Epoch 35/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7760\n","Epoch 36/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7760\n","Epoch 37/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 38/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 39/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 40/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 41/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 42/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 43/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 44/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 45/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 46/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 47/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 48/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 49/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 50/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 51/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 52/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 53/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 54/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 55/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 56/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 57/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 58/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 59/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 60/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 61/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 62/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 63/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 64/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 65/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7812\n","Epoch 66/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 67/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 68/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 69/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 70/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 71/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 72/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 73/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 74/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 75/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 76/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 77/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 78/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7812\n","Epoch 79/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 80/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 81/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 82/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 83/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 84/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 85/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 86/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 87/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 88/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 89/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7812\n","Epoch 90/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 91/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 92/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 93/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 94/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 95/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 96/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 97/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5006 - val_accuracy: 0.7812\n","Epoch 98/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 99/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 100/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 101/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 102/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 103/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7812\n","Epoch 104/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7812\n","Epoch 105/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7812\n","Epoch 106/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7812\n","Epoch 107/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7812\n","Epoch 108/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7812\n","Epoch 109/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7812\n","Epoch 110/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 111/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 112/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 113/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 114/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7760\n","Epoch 115/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 116/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 117/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 118/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 119/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7760\n","Epoch 120/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7708\n","Epoch 121/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7708\n","Epoch 122/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7708\n","Epoch 123/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7708\n","Epoch 124/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7708\n","Epoch 125/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n","Epoch 126/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n","Epoch 127/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n","Epoch 128/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n","Epoch 129/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7708\n","Epoch 130/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7708\n","Epoch 131/1000\n","18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7656\n","Epoch 132/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7656\n","Epoch 133/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7656\n","Epoch 134/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7656\n","Epoch 135/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7656\n","Epoch 136/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7656\n","Epoch 137/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7656\n","Epoch 138/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7656\n","Epoch 139/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7656\n","Epoch 140/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7656\n","Epoch 141/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7656\n","Epoch 142/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7656\n","Epoch 143/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7656\n","Epoch 144/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7708\n","Epoch 145/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7708\n","Epoch 146/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7708\n","Epoch 147/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7708\n","Epoch 148/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7708\n","Epoch 149/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7708\n","Epoch 150/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7708\n","Epoch 151/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7708\n","Epoch 152/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7708\n","Epoch 153/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7708\n","Epoch 154/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7708\n","Epoch 155/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7708\n","Epoch 156/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n","Epoch 157/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n","Epoch 158/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n","Epoch 159/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n","Epoch 160/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n","Epoch 161/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7708\n","Epoch 162/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7708\n","Epoch 163/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7708\n","Epoch 164/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7708\n","Epoch 165/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7708\n","Epoch 166/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7708\n","Epoch 167/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7708\n","Epoch 168/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7708\n","Epoch 169/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7708\n","Epoch 170/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n","Epoch 171/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5021 - val_accuracy: 0.7708\n","Epoch 172/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n","Epoch 173/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n","Epoch 174/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n","Epoch 175/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n","Epoch 176/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n","Epoch 177/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n","Epoch 178/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n","Epoch 179/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7778 - val_loss: 0.5023 - val_accuracy: 0.7708\n","Epoch 180/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7708\n","Epoch 181/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7708\n","Epoch 182/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7708\n","Epoch 183/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7708\n","Epoch 184/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7708\n","Epoch 185/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7708\n","Epoch 186/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7708\n","Epoch 187/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7708\n","Epoch 188/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7708\n","Epoch 189/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7708\n","Epoch 190/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7656\n","Epoch 191/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7656\n","Epoch 192/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7656\n","Epoch 193/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7656\n","Epoch 194/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7656\n","Epoch 195/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7656\n","Epoch 196/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 197/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 198/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 199/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 200/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7656\n","Epoch 201/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 202/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 203/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 204/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 205/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 206/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7656\n","Epoch 207/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n","Epoch 208/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n","Epoch 209/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n","Epoch 210/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n","Epoch 211/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7656\n","Epoch 212/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7656\n","Epoch 213/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7656\n","Epoch 214/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7656\n","Epoch 215/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7656\n","Epoch 216/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7656\n","Epoch 217/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7656\n","Epoch 218/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7656\n","Epoch 219/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7656\n","Epoch 220/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n","Epoch 221/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7656\n","Epoch 222/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7656\n","Epoch 223/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n","Epoch 224/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 225/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 226/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 227/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 228/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7656\n","Epoch 229/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n","Epoch 230/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n","Epoch 231/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7656\n","Epoch 232/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7656\n","Epoch 233/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7656\n","Epoch 234/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 235/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 236/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 237/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 238/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 239/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 240/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 241/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 242/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 243/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 244/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7656\n","Epoch 245/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 246/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 247/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 248/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 249/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 250/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 251/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 252/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 253/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 254/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 255/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7656\n","Epoch 256/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 257/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 258/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 259/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 260/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 261/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 262/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 263/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 264/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7778 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 265/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 266/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 267/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7656\n","Epoch 268/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 269/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 270/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 271/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 272/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 273/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 274/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 275/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 276/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 277/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 278/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 279/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 280/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 281/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 282/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7656\n","Epoch 283/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 284/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 285/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 286/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 287/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 288/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 289/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 290/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 291/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7656\n","Epoch 292/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 293/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 294/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 295/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 296/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 297/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 298/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 299/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7656\n","Epoch 300/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 301/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 302/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 303/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 304/1000\n","18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 305/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 306/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 307/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7656\n","Epoch 308/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 309/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 310/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 311/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 312/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 313/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 314/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 315/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 316/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7656\n","Epoch 317/1000\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7656\n","Epoch 318/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7656\n","Epoch 319/1000\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7656\n","Epoch 320/1000\n"," 1/18 [>.............................] - ETA: 0s - loss: 0.3311 - accuracy: 0.9062"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-1c151236d24e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Note that when we call \"fit\" again, it picks up where it left off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_hist_1b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"RdcgP9bXjyGD"},"source":["n = len(run_hist_1.history[\"loss\"])\n","m = len(run_hist_1b.history['loss'])\n","fig, ax = plt.subplots(figsize=(16, 8))\n","\n","ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n","ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n","\n","ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n","ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n","\n","ax.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRf5Z3PwjyGG"},"source":["Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"]},{"cell_type":"code","metadata":{"id":"wueYWo5vjyGH"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zL9m2U8gjyGJ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uG4Qud6EjyGL"},"source":["## Exercise\n","Now it's your turn.  Do the following in the cells below:\n","- Build a model with two hidden layers, each with 6 nodes\n","- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n","- Use a learning rate of .003 and train for 1500 epochs\n","- Graph the trajectory of the loss functions, accuracy on both train and test set\n","- Plot the roc curve for the predictions\n","\n","Experiment with different learning rates, numbers of epochs, and network structures"]},{"cell_type":"code","metadata":{"id":"0NdA7H9OjyGM"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AaQiKnDpjyGN"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s2FObFlXjyGQ"},"source":["## SOLUTION"]},{"cell_type":"code","metadata":{"id":"MdX-HEtojyGR"},"source":["model_2 = \n","\n","# compile\n","\n","# fit\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6E0reVKjyGV"},"source":["# plot loss and accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAmC1kccjyGY"},"source":["# Plot ROC curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5z1GLPSwjyGb"},"source":[],"execution_count":null,"outputs":[]}]}