{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Qw0lEaGuA5ujhlzazryyuF-nkWR5Zvum","timestamp":1664785468233},{"file_id":"1b4eEtgpKrHIvSZGGQs63Z4YB6hv0G7_j","timestamp":1635431799603}],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q9V45VKOZFei"},"source":["# Intro to Neural Networks\n","\n","## Exercise: neurons as logic gates\n","In this exercise we will experiment with neuron computations.  We will show how to represent basic logic functions like AND, OR, and XOR using single neurons (or more complicated structures).  Finally, at the end we will walk through how to represent neural networks as a chain of matrix computations."]},{"cell_type":"code","metadata":{"id":"X353-7ErZFek"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sdX4jZY9ZFep"},"source":["### Sigmoid function:\n","\n","$$\n","\\sigma = \\frac{1}{1 + e^{-x}}\n","$$\n","\n","$\\sigma$ ranges from (0, 1). When the input $x$ is negative, $\\sigma$ is close to 0. When $x$ is positive, $\\sigma$ is close to 1. At $x=0$, $\\sigma=0.5$"]},{"cell_type":"code","metadata":{"id":"55-go285ZFeq"},"source":["## Quickly define the sigmoid function\n","def sigmoid(x):\n","    \"\"\"Sigmoid function\"\"\"\n","    return 1.0 / (1.0 + np.exp(-x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b40xpSlMZFeu","colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"status":"ok","timestamp":1635432156013,"user_tz":-120,"elapsed":389,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"7ece0a21-eedb-447c-9c9b-1dfc956c65c0"},"source":["# Plot the sigmoid function\n","vals = np.linspace(-10, 10, num=100, dtype=np.float32)\n","activation = sigmoid(vals)\n","fig = plt.figure(figsize=(12,6))\n","fig.suptitle('Sigmoid function')\n","plt.plot(vals, activation)\n","plt.grid(True, which='both')\n","plt.axhline(y=0, color='k')\n","plt.axvline(x=0, color='k')\n","plt.yticks() # forces the presence of values on y axis\n","plt.ylim([-0.5, 1.5]);\n","# plt.show() if you run this code on your computer (to open a window with the plot)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"NGa-Y90yZFe0"},"source":["### Thinking of neurons as boolean logic \n","###Un singolo neurone prova a modellare la funzione OR\n","---\n","\n","gates\n","\n","A logic gate takes in two boolean (true/false or 1/0) inputs, and returns either a 0 or 1 depending on its rule. The truth table for a logic gate shows the outputs for each combination of inputs, (0, 0), (0, 1), (1,0), and (1, 1). For example, let's look at the truth table for an \"OR\" gate:\n","\n","### OR Gate\n","\n","<table>\n","\n","<tr>\n","<th colspan=\"3\">OR gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","</table>\n","\n","A neuron that uses the sigmoid activation function outputs a value between (0, 1). This naturally leads us to think about boolean values. Imagine a neuron that takes in two inputs, $x_1$ and $x_2$, and a bias term.\n","\n","By limiting the inputs of $x_1$ and $x_2$ to be in $\\left\\{0, 1\\right\\}$, we can simulate the effect of logic gates with our neuron. The goal is to find the weights, such that it returns an output close to 0 or 1 depending on the inputs.\n","\n","What numbers for the weights would we need to fill in for this gate to output OR logic? Observe from the plot above that $\\sigma(z)$ is close to 0 when $z$ is largely negative (around -10 or less), and is close to 1 when $z$ is largely positive (around +10 or greater).\n","\n","$$\n","z = w_1 x_1 + w_2 x_2 + b\n","$$\n","\n","Regressione lineare classica, conosco x1, x2 e devo inserire i pesi.\n","In questo caso il risultato deve essere molto negativo quando x1,x2 sono uguali a zero mentre positivo se ci sono degli 1\n","\n","Ad esempio:<br>\n","b = -10<br>\n","w1, w2 = 20\n","\n","\n","Let's think this through:\n","\n","* When $x_1$ and $x_2$ are both 0, the only value affecting $z$ is $b$. Because we want the result for (0, 0) to be close to zero, $b$ should be negative (at least -10)\n","* If either $x_1$ or $x_2$ is 1, we want the output to be close to 1. That means the weights associated with $x_1$ and $x_2$ should be enough to offset $b$ to the point of causing $z$ to be at least 10.\n","* Let's give $b$ a value of -10. How big do we need $w_1$ and $w_2$ to be? \n","    * At least +20\n","* So let's try out $w_1=20$, $w_2=20$, and $b=-10$!\n","\n"]},{"cell_type":"code","metadata":{"id":"mkP-qgVnZFe2"},"source":["def logic_gate(w1, w2, b, x1, x2):\n","    return sigmoid(w1 * x1 + w2 * x2 + b)\n","\n","def test(w1, w2, b):\n","    # Helper function to test out our weight functions.\n","    for x1, x2 in (0, 0), (0, 1), (1, 0), (1, 1):\n","        print(\"{}, {}: {}\".format(x1, x2, np.round(logic_gate(w1, w2, b, x1, x2))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VNPUJSjZFe5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156014,"user_tz":-120,"elapsed":13,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"696e1e3c-e324-4382-ea5f-c973e40723fe"},"source":["test(20, 20, -10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 0: 0.0\n","0, 1: 1.0\n","1, 0: 1.0\n","1, 1: 1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"WAy8VKPWZFe-"},"source":["<table>\n","\n","<tr>\n","<th colspan=\"3\">OR gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","</table>\n","\n","This matches! Great! Now you try finding the appropriate weight values for each truth table. Try not to guess and check- think through it logically and try to derive values that work.\n","\n","### AND Gate\n","\n","<table>\n","\n","<tr>\n","<th colspan=\"3\">AND gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"W1XyyFyGZFe_"},"source":["## Exercise\n","Try to figure out what values for the neurons would make this function as an AND gate."]},{"cell_type":"code","metadata":{"id":"JUIDVVCLZFfA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156388,"user_tz":-120,"elapsed":384,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"4d6812bd-c124-44d0-b653-8227a91bb8a1"},"source":["# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n","w1 = 20\n","w2 = 20\n","b = -30\n","\n","test(w1, w2, b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 0: 0.0\n","0, 1: 0.0\n","1, 0: 0.0\n","1, 1: 1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"DqadyhHoZFfG"},"source":["## Exercise\n","Do the same for the NOR gate and the NAND gate."]},{"cell_type":"markdown","metadata":{"id":"-wT334v7ZFfH"},"source":["### NOR (Not Or) Gate\n","\n","<table>\n","\n","<tr>\n","<th colspan=\"3\">NOR gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>0</td>\n","</tr>\n","\n","</table>"]},{"cell_type":"code","metadata":{"id":"XS5IHB1-ZFfI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156388,"user_tz":-120,"elapsed":41,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"de09bfb5-437b-4bf3-c136-353ec7af746f"},"source":["# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n","w1 = -20\n","w2 = -20\n","b = 10\n","\n","test(w1, w2, b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 0: 1.0\n","0, 1: 0.0\n","1, 0: 0.0\n","1, 1: 0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"e8auWjqcZFfN"},"source":["### NAND (Not And) Gate\n","\n","<table>\n","\n","<tr>\n","<th colspan=\"3\">NAND gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>0</td>\n","</tr>\n","\n","</table>"]},{"cell_type":"code","metadata":{"id":"7jJN6VWrZFfO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156389,"user_tz":-120,"elapsed":38,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"21342772-8eb3-4c83-c197-d27ae57d3e36"},"source":["# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n","w1 = -20\n","w2 = -20\n","b = 30\n","\n","test(w1, w2, b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 0: 1.0\n","0, 1: 1.0\n","1, 0: 1.0\n","1, 1: 0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"qt--teBRZFfS"},"source":["## The limits of single neurons\n","\n","If you've taken computer science courses, you may know that the XOR gates are the basis of computation. They can be used as so-called \"half-adders\", the foundation of being able to add numbers together. Here's the truth table for XOR:\n","\n","### XOR (Exclusive Or) Gate\n","\n","<table>\n","\n","<tr>\n","<th colspan=\"3\">XOR gate truth table</th>\n","</tr>\n","\n","<tr>\n","<th colspan=\"2\">Input</th>\n","<th>Output</th>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>0</td>\n","<td>0</td>\n","</tr>\n","\n","<tr>\n","<td>0</td>\n","<td>1</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","\n","<tr>\n","<td>1</td>\n","<td>1</td>\n","<td>0</td>\n","</tr>\n","\n","</table>\n","\n","Now the question is, can you create a set of weights such that a single neuron can output this property?\n","\n","It turns out that you cannot. Single neurons can't correlate inputs, so it's just confused. So individual neurons are out. Can we still use neurons to somehow form an XOR gate?\n","\n","What if we tried something more complex:\n","\n","![](images/logic03.png)\n","\n","Here, we've got the inputs going to two separate gates: the top neuron is an OR gate, and the bottom is a NAND gate. The output of these gates then get passed to another neuron, which is an AND gate. If you work out the outputs at each combination of input values, you'll see that this is an XOR gate!"]},{"cell_type":"code","metadata":{"id":"wxyd4749ZFfT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156389,"user_tz":-120,"elapsed":33,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"f699053a-e31b-4ab9-b43c-f036b9c3a6ee"},"source":["def or_gate(x1, x2):\n","    # Use the values found above\n","    w1 = 20\n","    w2 = 20\n","    b = -10\n","    return sigmoid(w1 * x1 + w2 * x2 + b) #funzione di attivazione\n","\n","def and_gate(x1, x2):\n","    w1 = 20\n","    w2 = 20\n","    b = -30\n","    return sigmoid(w1 * x1 + w2 * x2 + b)\n","\n","def nand_gate(x1, x2):\n","    w1 = -20\n","    w2 = -20\n","    b = 30\n","    return sigmoid(w1 * x1 + w2 * x2 + b)\n","\n","# Make sure you have or_gate, nand_gate, and and_gate working from above!\n","# 2 strati \n","#primo: (uno con un neurone che calcola or e uno con nand)\n","#secondo: calcolo and del risultato dei due strati precedenti\n","def xor_gate(a, b):\n","    c = or_gate(a, b)\n","    d = nand_gate(a, b)\n","    return and_gate(c, d)\n","\n","def test():\n","    # Helper function to test out our weight functions.\n","    for x1, x2 in (0, 0), (0, 1), (1, 0), (1, 1):\n","        print(\"{}, {}: {}\".format(x1, x2, np.round(xor_gate(x1, x2))))\n","\n","test()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 0: 0.0\n","0, 1: 1.0\n","1, 0: 1.0\n","1, 1: 0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"5-Bkr34mZFfY"},"source":["## Feedforward Networks as Matrix Computations\n","\n","We discussed previously how the feed-forward computation of a neural network can be thought of as matrix calculations and activation functions.  We will do some actual computations with matrices to see this in action.\n","\n","PASSAGGIO IN AVANTI:\n","è un semplice calcolo matriciale\n","\n","![](images/FF_NN.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"blaw-XjAZFfZ"},"source":["## Exercise\n","Provided below are the following:\n","\n","- Three weight matrices `W_1`, `W_2` and `W_3` representing the weights in each layer.  The convention for these matrices is that each $W_{i,j}$ gives the weight from neuron $i$ in the previous (left) layer to neuron $j$ in the next (right) layer.  \n","- A vector `x_in` representing a single input and a matrix `x_mat_in` representing 7 different inputs.\n","- Two functions: `soft_max_vec` and `soft_max_mat` which apply the soft_max function to a single vector, and row-wise to a matrix.\n","\n","The goals for this exercise are:\n","1. For input `x_in` calculate the inputs and outputs to each layer (assuming sigmoid activations for the middle two layers and soft_max output for the final layer).\n","2. Write a function that does the entire neural network calculation for a single input\n","3. Write a function that does the entire neural network calculation for a matrix of inputs, where each row is a single input.\n","4. Test your functions on `x_in` and `x_mat_in`.\n","\n","This illustrates what happens in a NN during one single forward pass. Roughly speaking, after this forward pass, it remains to compare the output of the network to the known truth values, compute the gradient of the loss function and adjust the weight matrices `W_1`, `W_2` and `W_3` accordingly, and iterate. Hopefully this process will result in better weight matrices and our loss will be smaller afterwards."]},{"cell_type":"code","metadata":{"id":"-nVBRXiOZFfa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156390,"user_tz":-120,"elapsed":31,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"d11441d0-5e64-4b85-d635-bb59eb78c9d5"},"source":["#Modello la deep neural network \n","#conosco già i suoi pesi\n","#[2,-1,1,4] sono i pesi associati ai 4 rami in uscita di x1\n","W_1 = np.array([[2,-1,1,4],[-1,2,-3,1],[3,-2,-1,5]])\n","W_2 = np.array([[3,1,-2,1],[-2,4,1,-4],[-1,-3,2,-5],[3,1,1,1]])\n","W_3 = np.array([[-1,3,-2],[1,-1,-3],[3,-2,2],[1,2,1]])\n","x_in = np.array([.5,.8,.2]) #vettore di input\n","#Matrice di più possibili esempi di input\n","#effettuo i calcoli su n input contemporanemte in genere per maggiore efficienza\n","x_mat_in = np.array([[.5,.8,.2],[.1,.9,.6],[.2,.2,.3],[.6,.1,.9],[.5,.5,.4],[.9,.1,.9],[.1,.8,.7]])\n","\n","\n","print('the matrix W_1\\n')\n","print(W_1)\n","print('-'*30)\n","print('vector input x_in\\n')\n","print(x_in)\n","print ('-'*30)\n","print('matrix input x_mat_in -- starts with the vector `x_in`\\n')\n","print(x_mat_in)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the matrix W_1\n","\n","[[ 2 -1  1  4]\n"," [-1  2 -3  1]\n"," [ 3 -2 -1  5]]\n","------------------------------\n","vector input x_in\n","\n","[0.5 0.8 0.2]\n","------------------------------\n","matrix input x_mat_in -- starts with the vector `x_in`\n","\n","[[0.5 0.8 0.2]\n"," [0.1 0.9 0.6]\n"," [0.2 0.2 0.3]\n"," [0.6 0.1 0.9]\n"," [0.5 0.5 0.4]\n"," [0.9 0.1 0.9]\n"," [0.1 0.8 0.7]]\n"]}]},{"cell_type":"code","metadata":{"id":"_CNHCyeHZFfg"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jN1vuf6szIwD"},"source":["Follow this image for terminology\n","\n","![1st step of a NN](http://ml.unife.it/wp-content/uploads/2019/09/1st_step_NN.png)\n","\n","- `a_n` is the value in output from a neuron, i.e., neuron input's with activation\n","- `z_n` is the value in input to a neuron, i.e., previous neuron's output * weights"]},{"cell_type":"code","metadata":{"id":"gCcVZuN6ZFfj"},"source":["## Student to do the calculations below\n","\n","## Remember: (1) np.dot allows matrix multiplication;\n","##           (2) we have sigmoid function already defined"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIhusUjlZFfm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156392,"user_tz":-120,"elapsed":28,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"f24887f8-14b4-4acf-bc4a-a3f12971ee24"},"source":["z_2 = np.dot(x_in,W_1)\n","z_2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.8,  0.7, -2.1,  3.8])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"G3cvisfxZFfu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156392,"user_tz":-120,"elapsed":25,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"1441ec00-6a32-4a1e-a6cf-bc0e3377c08e"},"source":["#sigmoide porta i valori tra 0 e 1\n","a_2 = sigmoid(z_2)\n","a_2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.68997448, 0.66818777, 0.10909682, 0.97811873])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"rBXq0PeyZFf1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156393,"user_tz":-120,"elapsed":22,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"7beb1ed2-edca-40ad-9e03-6d3c3473fc80"},"source":["z_3 = np.dot(a_2,W_2)\n","z_3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3.55880727,  4.01355384,  0.48455118, -1.55014198])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"w6gCHgC0ZFgA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156393,"user_tz":-120,"elapsed":19,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"69079e74-0fc2-41a5-ec02-013f19c2af11"},"source":["a_3 = sigmoid(z_3)\n","a_3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.97231549, 0.98225163, 0.61882199, 0.17506576])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"HjkA21ZwZFgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156395,"user_tz":-120,"elapsed":19,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"5b0f8fa4-2b77-483d-f211-e9104d9793af"},"source":["z_4 = np.dot(a_3,W_3)\n","z_4"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.04146788,  1.04718238, -3.47867612])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"XSiXqaROZFgM"},"source":["#Funzione della SOFTMAX\n","# e^vec / somma(e^vec)\n","#eseguita su ogni elemento del vettore\n","def soft_max_vec(vec):\n","    return np.exp(vec)/(np.sum(np.exp(vec)))\n","\n","#risultato -> 3 valori che sommati danno uno\n","#crea una distribuzione di probabilità sull'uscita\n","\n","def soft_max_mat(mat):\n","    return np.exp(mat)/(np.sum(np.exp(mat),axis=1).reshape(-1,1))\n","    #                                       ^        ^\n","    # axis = 1 sums by row, = 0 sums by column       |\n","    # reshape used to set the shape of the matrix (rows, columns), -1 means that\n","    # the number is inferred by the number of elements in the matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RnBZCtjZFgP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156396,"user_tz":-120,"elapsed":17,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"2dc94977-850b-4115-aee6-2cfa36b5dc02"},"source":["y_out = soft_max_vec(z_4)\n","y_out\n","#prob di 0.72 di appartenere alla prima classe, 0.26 di appartenere alla seconda..."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.72780576, 0.26927918, 0.00291506])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"EgjF2pFuZFgU"},"source":["## A one-line function to do the entire neural net computation\n","\n","def nn_comp_vec(x):\n","    return soft_max_vec(sigmoid(sigmoid(np.dot(x,W_1)).dot(W_2)).dot(W_3))\n","\n","def nn_comp_mat(x):\n","    return soft_max_mat(sigmoid(sigmoid(np.dot(x,W_1)).dot(W_2)).dot(W_3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0Rj4xavZFgW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156397,"user_tz":-120,"elapsed":16,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"df8532ee-ed3f-4b63-8437-7615c51a0934"},"source":["nn_comp_vec(x_in)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.72780576, 0.26927918, 0.00291506])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"LTgSmDdRZFga","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635432156724,"user_tz":-120,"elapsed":9,"user":{"displayName":"Riccardo ZESE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXigVtCRknnXfK2USg1BNnkmnAW81shvO7DwSbsg=s64","userId":"04020535739779133030"}},"outputId":"3f13ec7d-a28e-4338-a036-f00928999c34"},"source":["nn_comp_mat(x_mat_in)\n","#Calcolo di più input in contemporanea\n","#la prima riga di risultato si riferisce alla prima riga di input\n","\n","#Se il modello fosse perfetto: 1, 0 ,0 come risultato\n","#In addestramento posso calcolare la loss della rete sugli output ottenuti\n","#calcolo la loss generale come somma di tutte le loss -> gradient descent"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.72780576, 0.26927918, 0.00291506],\n","       [0.62054212, 0.37682531, 0.00263257],\n","       [0.69267581, 0.30361576, 0.00370844],\n","       [0.36618794, 0.63016955, 0.00364252],\n","       [0.57199769, 0.4251982 , 0.00280411],\n","       [0.38373781, 0.61163804, 0.00462415],\n","       [0.52510443, 0.4725011 , 0.00239447]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"pfbNVwMcZFgd"},"source":[],"execution_count":null,"outputs":[]}]}